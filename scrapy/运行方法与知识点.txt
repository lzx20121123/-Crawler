运行：   打开cmd  ，进入到tencent 文件夹  ，输入 [[[   scrapy crawl tencentPostion（爬虫的名称） -o xxxx.csv    ]]]  回车运行

新建项目：
  scrapy startproject +项目名称
  
创建爬虫
  进入项目文件夹  输入：     scrapy genspider +爬虫名称

加日志的方法：sitting.py文件中，加入以下内容：
  #保存日志信息的文件名
  LOG_FILE = "musiclog.log"    （文件名）
  #保存日志等级，低于|等于此等级的信息都被保存（CRITICAL、ERROR、WARNING、DEBUG、INFO）
  LOG_LEVEL ="DEBUG"     （等级）

爬取的文本内容保存为csv\json文件的方法：
  scrapy crawl tencentPostion（爬虫的名称） -o xxxx.csv（文件名称）  
  scrapy crawl tencentPostion -o xxxx.json
